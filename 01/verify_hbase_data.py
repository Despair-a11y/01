"""
HBase æ•°æ®éªŒè¯è„šæœ¬
ç”¨äºéªŒè¯æ•°æ®æ˜¯å¦æ­£ç¡®å¯¼å…¥ HBase
"""
from hbase_connector import get_hbase_connector
from hbase_config import get_table_name
import pandas as pd


def verify_hbase_data():
    """éªŒè¯ HBase æ•°æ®"""
    
    print("=" * 60)
    print("HBase æ•°æ®éªŒè¯å·¥å…·")
    print("=" * 60)
    
    try:
        # è¿æ¥ HBase
        print("\nğŸ”Œ è¿æ¥ HBase...")
        connector = get_hbase_connector()
        
        if not connector.is_connected():
            print("âŒ æ— æ³•è¿æ¥åˆ° HBase")
            return
        
        print("âœ… HBase è¿æ¥æˆåŠŸ\n")
        
        # éªŒè¯ movies è¡¨
        print("=" * 60)
        print("éªŒè¯ Movies è¡¨")
        print("=" * 60)
        verify_movies_table(connector)
        
        # éªŒè¯ ratings è¡¨
        print("\n" + "=" * 60)
        print("éªŒè¯ Ratings è¡¨")
        print("=" * 60)
        verify_ratings_table(connector)
        
        # æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥
        print("\n" + "=" * 60)
        print("æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥")
        print("=" * 60)
        check_data_consistency(connector)
        
        # æ–­å¼€è¿æ¥
        connector.disconnect()
        
        print("\n" + "=" * 60)
        print("âœ… éªŒè¯å®Œæˆï¼")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ éªŒè¯å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def verify_movies_table(connector):
    """éªŒè¯ movies è¡¨"""
    try:
        # è¯»å–æ•°æ®
        print("ğŸ“– è¯»å– movies è¡¨æ•°æ®...")
        movies = connector.read_movies()
        
        print(f"âœ… æˆåŠŸè¯»å– {len(movies)} æ¡è®°å½•")
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        print("\nğŸ“‹ æ£€æŸ¥å­—æ®µå®Œæ•´æ€§:")
        required_fields = ['movieId', 'title', 'genres']
        for field in required_fields:
            if field in movies.columns:
                non_null = movies[field].notna().sum()
                null_count = movies[field].isna().sum()
                print(f"  - {field}: {non_null} éç©º, {null_count} ç©ºå€¼")
            else:
                print(f"  - {field}: âŒ ç¼ºå¤±")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - ç”µå½±IDèŒƒå›´: {movies['movieId'].min()} - {movies['movieId'].max()}")
        if 'year' in movies.columns:
            print(f"  - å¹´ä»½èŒƒå›´: {movies['year'].min():.0f} - {movies['year'].max():.0f}")
        
        # æ˜¾ç¤ºæ ·ä¾‹æ•°æ®
        print("\nğŸ“ æ ·ä¾‹æ•°æ®ï¼ˆå‰5æ¡ï¼‰:")
        print(movies.head(5).to_string())
        
        # æ£€æŸ¥é‡å¤æ•°æ®
        duplicates = movies['movieId'].duplicated().sum()
        if duplicates > 0:
            print(f"\nâš ï¸  è­¦å‘Š: å‘ç° {duplicates} æ¡é‡å¤çš„ movieId")
        else:
            print(f"\nâœ… æ— é‡å¤æ•°æ®")
        
    except Exception as e:
        print(f"âŒ Movies è¡¨éªŒè¯å¤±è´¥: {e}")


def verify_ratings_table(connector):
    """éªŒè¯ ratings è¡¨"""
    try:
        # è¯»å–æ•°æ®ï¼ˆé™åˆ¶æ•°é‡ä»¥é¿å…å†…å­˜æº¢å‡ºï¼‰
        print("ğŸ“– è¯»å– ratings è¡¨æ•°æ®...")
        
        # è·å–è¡¨å¯¹è±¡å¹¶æ‰«æ
        table_name = get_table_name('ratings')
        table = connector.get_table(table_name)
        
        # ç»Ÿè®¡æ€»è¡Œæ•°
        print("ğŸ“Š ç»Ÿè®¡è¡Œæ•°...")
        row_count = 0
        for _ in table.scan():
            row_count += 1
            if row_count % 10000 == 0:
                print(f"  å·²æ‰«æ {row_count} è¡Œ...")
        
        print(f"âœ… æ€»è¡Œæ•°: {row_count:,}")
        
        # è¯»å–æ ·ä¾‹æ•°æ®
        print("\nğŸ“– è¯»å–æ ·ä¾‹æ•°æ®ï¼ˆå‰1000æ¡ï¼‰...")
        sample_data = []
        for i, (key, value) in enumerate(table.scan(limit=1000)):
            row = {}
            for col, val in value.items():
                col_name = col.decode().split(':')[1]
                row[col_name] = val.decode()
            sample_data.append(row)
        
        ratings_sample = pd.DataFrame(sample_data)
        
        # æ£€æŸ¥å¿…è¦å­—æ®µ
        print("\nğŸ“‹ æ£€æŸ¥å­—æ®µå®Œæ•´æ€§:")
        required_fields = ['userId', 'movieId', 'rating', 'timestamp']
        for field in required_fields:
            if field in ratings_sample.columns:
                non_null = ratings_sample[field].notna().sum()
                null_count = ratings_sample[field].isna().sum()
                print(f"  - {field}: {non_null} éç©º, {null_count} ç©ºå€¼")
            else:
                print(f"  - {field}: âŒ ç¼ºå¤±")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼ˆåŸºäºæ ·ä¾‹ï¼‰:")
        if 'userId' in ratings_sample.columns:
            ratings_sample['userId'] = pd.to_numeric(ratings_sample['userId'], errors='coerce')
            print(f"  - ç”¨æˆ·IDèŒƒå›´: {ratings_sample['userId'].min():.0f} - {ratings_sample['userId'].max():.0f}")
        
        if 'rating' in ratings_sample.columns:
            ratings_sample['rating'] = pd.to_numeric(ratings_sample['rating'], errors='coerce')
            print(f"  - è¯„åˆ†èŒƒå›´: {ratings_sample['rating'].min()} - {ratings_sample['rating'].max()}")
            print(f"  - å¹³å‡è¯„åˆ†: {ratings_sample['rating'].mean():.2f}")
        
        # æ˜¾ç¤ºæ ·ä¾‹æ•°æ®
        print("\nğŸ“ æ ·ä¾‹æ•°æ®ï¼ˆå‰5æ¡ï¼‰:")
        print(ratings_sample.head(5).to_string())
        
    except Exception as e:
        print(f"âŒ Ratings è¡¨éªŒè¯å¤±è´¥: {e}")


def check_data_consistency(connector):
    """æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§"""
    try:
        print("ğŸ“‹ æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§...")
        
        # è¯»å–æ•°æ®
        movies = connector.read_movies()
        
        # ä» ratings è¡¨è¯»å–æ ·ä¾‹æ•°æ®
        table_name = get_table_name('ratings')
        table = connector.get_table(table_name)
        
        sample_data = []
        for i, (key, value) in enumerate(table.scan(limit=1000)):
            row = {}
            for col, val in value.items():
                col_name = col.decode().split(':')[1]
                row[col_name] = val.decode()
            sample_data.append(row)
        
        ratings_sample = pd.DataFrame(sample_data)
        
        if 'movieId' in ratings_sample.columns:
            ratings_sample['movieId'] = pd.to_numeric(ratings_sample['movieId'], errors='coerce')
            
            # æ£€æŸ¥å¼•ç”¨å®Œæ•´æ€§
            movie_ids_in_movies = set(movies['movieId'])
            movie_ids_in_ratings = set(ratings_sample['movieId'].dropna())
            
            # æ‰¾å‡º ratings ä¸­ä½†ä¸åœ¨ movies ä¸­çš„ movieId
            orphan_movies = movie_ids_in_ratings - movie_ids_in_movies
            
            print(f"\n  - Movies è¡¨ä¸­çš„ç”µå½±æ•°: {len(movie_ids_in_movies)}")
            print(f"  - Ratings æ ·ä¾‹ä¸­æ¶‰åŠçš„ç”µå½±æ•°: {len(movie_ids_in_ratings)}")
            
            if orphan_movies:
                print(f"  - âš ï¸  å‘ç° {len(orphan_movies)} ä¸ªå­¤å„¿ç”µå½±IDï¼ˆåœ¨ratingsä¸­ä½†ä¸åœ¨moviesä¸­ï¼‰")
                print(f"    ç¤ºä¾‹: {list(orphan_movies)[:5]}")
            else:
                print(f"  - âœ… å¼•ç”¨å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
        
        # æ£€æŸ¥è¯„åˆ†å€¼èŒƒå›´
        if 'rating' in ratings_sample.columns:
            ratings_sample['rating'] = pd.to_numeric(ratings_sample['rating'], errors='coerce')
            valid_ratings = ratings_sample['rating'].dropna()
            invalid_ratings = valid_ratings[(valid_ratings < 0.5) | (valid_ratings > 5.0)]
            
            if len(invalid_ratings) > 0:
                print(f"  - âš ï¸  å‘ç° {len(invalid_ratings)} ä¸ªæ— æ•ˆè¯„åˆ†å€¼")
            else:
                print(f"  - âœ… è¯„åˆ†å€¼èŒƒå›´æ£€æŸ¥é€šè¿‡ï¼ˆ0.5-5.0ï¼‰")
        
    except Exception as e:
        print(f"âŒ ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {e}")


if __name__ == '__main__':
    verify_hbase_data()

